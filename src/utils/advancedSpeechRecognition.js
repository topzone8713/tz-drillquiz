/**
 * ê³ ê¸‰ ìŒì„±ì¸ì‹ ìœ í‹¸ë¦¬í‹°
 * Web Speech APIì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ ëŒ€ì•ˆ êµ¬í˜„
 */

import { debugLog } from './debugUtils'

export class AdvancedSpeechRecognition {
  constructor(options = {}) {
    this.options = {
      primaryEngine: 'web-speech', // 'web-speech', 'google-cloud', 'azure', 'aws'
      fallbackEngines: ['google-cloud', 'azure'],
      confidenceThreshold: 0.7,
      maxRetries: 3,
      retryDelay: 1000,
      ...options
    }
    
    this.currentEngine = this.options.primaryEngine
    this.retryCount = 0
    this.isListening = false
    this.recognitionInstance = null
  }

  /**
   * ìŒì„±ì¸ì‹ ì‹œì‘
   */
  async startListening() {
    try {
      debugLog('ğŸ¤ [ê³ ê¸‰ ìŒì„±ì¸ì‹] ìŒì„±ì¸ì‹ ì‹œì‘:', {
        engine: this.currentEngine,
        options: this.options
      })

      this.isListening = true
      this.retryCount = 0

      switch (this.currentEngine) {
        case 'web-speech':
          return await this.startWebSpeechRecognition()
        case 'google-cloud':
          return await this.startGoogleCloudRecognition()
        case 'azure':
          return await this.startAzureRecognition()
        case 'aws':
          return await this.startAWSRecognition()
        default:
          throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŒì„±ì¸ì‹ ì—”ì§„: ${this.currentEngine}`)
      }
    } catch (error) {
      debugLog('ğŸ¤ [ê³ ê¸‰ ìŒì„±ì¸ì‹] ìŒì„±ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨:', error, 'error')
      return await this.handleRecognitionError(error)
    }
  }

  /**
   * Web Speech API ì‚¬ìš©
   */
  async startWebSpeechRecognition() {
    return new Promise((resolve, reject) => {
      if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
        reject(new Error('Web Speech APIë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.'))
        return
      }

      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      this.recognitionInstance = new SpeechRecognition()
      
      // ìµœì í™”ëœ ì„¤ì •
      this.recognitionInstance.continuous = true
      this.recognitionInstance.interimResults = true
      this.recognitionInstance.maxAlternatives = 5 // ë” ë§ì€ ëŒ€ì•ˆ ìˆ˜ì§‘
      this.recognitionInstance.lang = this.options.language || 'ko-KR'

      this.recognitionInstance.onstart = () => {
        debugLog('ğŸ¤ [Web Speech] ìŒì„±ì¸ì‹ ì‹œì‘ë¨')
        resolve()
      }

      this.recognitionInstance.onresult = (event) => {
        this.handleRecognitionResult(event)
      }

      this.recognitionInstance.onerror = (error) => {
        debugLog('ğŸ¤ [Web Speech] ì˜¤ë¥˜ ë°œìƒ:', error, 'error')
        this.handleRecognitionError(error)
      }

      this.recognitionInstance.onend = () => {
        debugLog('ğŸ¤ [Web Speech] ìŒì„±ì¸ì‹ ì¢…ë£Œë¨')
        if (this.isListening) {
          // ìë™ ì¬ì‹œì‘
          setTimeout(() => this.startListening(), 1000)
        }
      }

      this.recognitionInstance.start()
    })
  }

  /**
   * Google Cloud Speech-to-Text API ì‚¬ìš©
   */
  async startGoogleCloudRecognition() {
    // Google Cloud Speech-to-Text API êµ¬í˜„
    // ì‹¤ì œ êµ¬í˜„ ì‹œ API í‚¤ì™€ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤
    debugLog('ğŸ¤ [Google Cloud] ìŒì„±ì¸ì‹ ì‹œì‘ (êµ¬í˜„ ì˜ˆì •)')
    throw new Error('Google Cloud Speech-to-TextëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
  }

  /**
   * Azure Speech Services ì‚¬ìš©
   */
  async startAzureRecognition() {
    // Azure Speech Services êµ¬í˜„
    debugLog('ğŸ¤ [Azure] ìŒì„±ì¸ì‹ ì‹œì‘ (êµ¬í˜„ ì˜ˆì •)')
    throw new Error('Azure Speech ServicesëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
  }

  /**
   * AWS Transcribe ì‚¬ìš©
   */
  async startAWSRecognition() {
    // AWS Transcribe êµ¬í˜„
    debugLog('ğŸ¤ [AWS] ìŒì„±ì¸ì‹ ì‹œì‘ (êµ¬í˜„ ì˜ˆì •)')
    throw new Error('AWS TranscribeëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
  }

  /**
   * ìŒì„±ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬
   */
  handleRecognitionResult(event) {
    let finalTranscript = ''
    let interimTranscript = ''
    let bestConfidence = 0

    for (let i = event.resultIndex; i < event.results.length; i++) {
      const result = event.results[i]
      const isFinal = result.isFinal

      // ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ëŒ€ì•ˆ ì„ íƒ
      let bestAlternative = result[0]
      for (let j = 0; j < result.length; j++) {
        if (result[j].confidence > bestAlternative.confidence) {
          bestAlternative = result[j]
        }
      }

      const transcript = bestAlternative.transcript
      const confidence = bestAlternative.confidence

      if (isFinal) {
        if (confidence >= this.options.confidenceThreshold) {
          finalTranscript += transcript
          if (confidence > bestConfidence) {
            bestConfidence = confidence
          }
        } else {
          debugLog('ğŸ¤ [ê³ ê¸‰ ìŒì„±ì¸ì‹] ë‚®ì€ ì‹ ë¢°ë„ë¡œ ì¸í•œ ê²°ê³¼ ì œì™¸:', {
            transcript,
            confidence,
            threshold: this.options.confidenceThreshold
          })
        }
      } else {
        interimTranscript += transcript
      }
    }

    // ê²°ê³¼ ì´ë²¤íŠ¸ ë°œìƒ
    if (finalTranscript) {
      this.emit('result', {
        transcript: finalTranscript,
        confidence: bestConfidence,
        isFinal: true,
        engine: this.currentEngine
      })
    }

    if (interimTranscript) {
      this.emit('interim', {
        transcript: interimTranscript,
        isFinal: false,
        engine: this.currentEngine
      })
    }
  }

  /**
   * ìŒì„±ì¸ì‹ ì˜¤ë¥˜ ì²˜ë¦¬ ë° í´ë°±
   */
  async handleRecognitionError(error) {
    debugLog('ğŸ¤ [ê³ ê¸‰ ìŒì„±ì¸ì‹] ì˜¤ë¥˜ ì²˜ë¦¬:', {
      error: error.message,
      currentEngine: this.currentEngine,
      retryCount: this.retryCount
    })

    if (this.retryCount < this.options.maxRetries) {
      this.retryCount++
      
      // í´ë°± ì—”ì§„ìœ¼ë¡œ ì „í™˜
      const fallbackIndex = (this.retryCount - 1) % this.options.fallbackEngines.length
      this.currentEngine = this.options.fallbackEngines[fallbackIndex]
      
      debugLog('ğŸ¤ [ê³ ê¸‰ ìŒì„±ì¸ì‹] í´ë°± ì—”ì§„ìœ¼ë¡œ ì „í™˜:', {
        newEngine: this.currentEngine,
        retryCount: this.retryCount
      })

      // ì§€ì—° í›„ ì¬ì‹œë„
      setTimeout(() => {
        this.startListening()
      }, this.options.retryDelay * this.retryCount)
    } else {
      this.emit('error', {
        message: 'ëª¨ë“  ìŒì„±ì¸ì‹ ì—”ì§„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        originalError: error,
        engines: [this.options.primaryEngine, ...this.options.fallbackEngines]
      })
    }
  }

  /**
   * ìŒì„±ì¸ì‹ ì¤‘ì§€
   */
  stopListening() {
    debugLog('ğŸ¤ [ê³ ê¸‰ ìŒì„±ì¸ì‹] ìŒì„±ì¸ì‹ ì¤‘ì§€')
    this.isListening = false

    if (this.recognitionInstance) {
      if (this.currentEngine === 'web-speech') {
        this.recognitionInstance.stop()
      }
      this.recognitionInstance = null
    }
  }

  /**
   * ì´ë²¤íŠ¸ ë°œìƒ
   */
  emit(event, data) {
    if (this.options.onResult && event === 'result') {
      this.options.onResult(data)
    }
    if (this.options.onInterim && event === 'interim') {
      this.options.onInterim(data)
    }
    if (this.options.onError && event === 'error') {
      this.options.onError(data)
    }
  }

  /**
   * ì—”ì§„ ì „í™˜
   */
  switchEngine(engine) {
    if (this.isListening) {
      this.stopListening()
    }
    
    this.currentEngine = engine
    this.retryCount = 0
    
    debugLog('ğŸ¤ [ê³ ê¸‰ ìŒì„±ì¸ì‹] ì—”ì§„ ì „í™˜:', {
      newEngine: engine
    })
  }

  /**
   * ì„¤ì • ì—…ë°ì´íŠ¸
   */
  updateOptions(newOptions) {
    this.options = { ...this.options, ...newOptions }
    debugLog('ğŸ¤ [ê³ ê¸‰ ìŒì„±ì¸ì‹] ì„¤ì • ì—…ë°ì´íŠ¸:', this.options)
  }
}

/**
 * ìŒì„±ì¸ì‹ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ì „ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
 */
export class VoicePreprocessor {
  constructor() {
    this.audioContext = null
    this.analyser = null
    this.microphone = null
  }

  /**
   * ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
   */
  async initializeAudioContext() {
    try {
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)()
      this.analyser = this.audioContext.createAnalyser()
      this.analyser.fftSize = 256
      
      debugLog('ğŸ¤ [ì „ì²˜ë¦¬] ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ')
      return true
    } catch (error) {
      debugLog('ğŸ¤ [ì „ì²˜ë¦¬] ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨:', error, 'error')
      return false
    }
  }

  /**
   * ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
   */
  async setupMicrophone() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100
        } 
      })
      
      this.microphone = this.audioContext.createMediaStreamSource(stream)
      this.microphone.connect(this.analyser)
      
      debugLog('ğŸ¤ [ì „ì²˜ë¦¬] ë§ˆì´í¬ ì„¤ì • ì™„ë£Œ')
      return stream
    } catch (error) {
      debugLog('ğŸ¤ [ì „ì²˜ë¦¬] ë§ˆì´í¬ ì„¤ì • ì‹¤íŒ¨:', error, 'error')
      throw error
    }
  }

  /**
   * ìŒì„± í’ˆì§ˆ ë¶„ì„
   */
  analyzeVoiceQuality() {
    if (!this.analyser) return null

    const bufferLength = this.analyser.frequencyBinCount
    const dataArray = new Uint8Array(bufferLength)
    this.analyser.getByteFrequencyData(dataArray)

    // í‰ê·  ë³¼ë¥¨ ê³„ì‚°
    const average = dataArray.reduce((a, b) => a + b) / bufferLength
    
    // ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„ ì¶”ì •
    const signal = Math.max(...dataArray)
    const noise = dataArray.reduce((a, b) => a + b) / bufferLength
    const snr = signal / (noise + 1) // 1ì„ ë”í•´ì„œ 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€

    return {
      volume: average,
      signalToNoiseRatio: snr,
      quality: this.calculateQualityScore(average, snr)
    }
  }

  /**
   * í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
   */
  calculateQualityScore(volume, snr) {
    // ë³¼ë¥¨ì´ ë„ˆë¬´ ë‚®ê±°ë‚˜ ë†’ìœ¼ë©´ í’ˆì§ˆ ê°ì 
    const volumeScore = volume > 10 && volume < 200 ? 1 : 0.5
    
    // ì‹ í˜¸ ëŒ€ ì¡ìŒë¹„ê°€ ë†’ì„ìˆ˜ë¡ ì¢‹ì€ í’ˆì§ˆ
    const snrScore = Math.min(snr / 10, 1)
    
    return (volumeScore + snrScore) / 2
  }

  /**
   * ì •ë¦¬
   */
  cleanup() {
    if (this.microphone) {
      this.microphone.disconnect()
      this.microphone = null
    }
    if (this.audioContext) {
      this.audioContext.close()
      this.audioContext = null
    }
  }
}

export default AdvancedSpeechRecognition
